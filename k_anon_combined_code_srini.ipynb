{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ff51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS cluster configuration for below\n",
    "# Master node: r5.2x large\n",
    "# core node : m4.4x large \n",
    "# Tasknode node: m5.4x large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3751463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%configure` not found.\n"
     ]
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"conf\":{\"spark.driver.maxResultSize\":\"15G\",\n",
    "         \"spark.executor.memory\": \"30G\",\n",
    "         \"spark.executor.cores\": \"16\",\n",
    "         \"spark.driver.memory\": \"25G\",\n",
    "         \"spark.executor.memoryOverhead\":\"22G\",\n",
    "         \"spark.dynamicAllocation.enabled\":\"true\",\n",
    "         \"spark.dynamicAllocation.minExecutors\":\"20\",\n",
    "         \"spark.shuffle.service.enabled\":\"true\",\n",
    "         \"spark.network.timeout\":\"1000000\",\n",
    "         \"spark.sql.shuffle.partitions\":\"3001\",\n",
    "         \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "         \"spark.pyspark.python\": \"python3\",\n",
    "         \"spark.pyspark.virtualenv.type\": \"native\",\n",
    "         \"spark.pyspark.virtualenv.bin.path\": \"/usr/bin/virtualenv\"},\n",
    "\"kind\": \"pyspark\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d875e3c-6b65-456a-b1ad-d4b0ff729459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21795/3453896304.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>div.jp-OutputArea-output pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.jp-OutputArea-output pre {white-space: pre;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "808fb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import re \n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9af0bfb-feab-4d51-8f6d-a77987067904",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a spark session\n",
    "spark = SparkSession.builder \\\n",
    ".enableHiveSupport()\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf0047",
   "metadata": {},
   "source": [
    "### Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa085db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Listing all the columns and passing numerical columns into numerical and categorical columns into categorical\n",
    "columns = ['age','fnlwgt','workclass','education','education_num','marital_status','occupation','relationship',\n",
    "    'race','sex','capital_gain','capital_loss','hours_per_week','native_country']\n",
    "\n",
    "numerical = set(('age','fnlwgt','education_num','capital_gain','capital_loss','hours_per_week'))\n",
    "categorical = set(('workclass','education','marital_status','occupation','relationship','sex','native_country','race'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d76802e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Defining the schema for all the variables\n",
    "schema = StructType([StructField('age', IntegerType(), True),\n",
    "                     StructField('workclass', StringType(), True),\n",
    "                     StructField('fnlwgt', LongType(), True),\n",
    "                     StructField('education', StringType(), True),\n",
    "                     StructField('education_num', IntegerType(), True),\n",
    "                     StructField('marital_status', StringType(), True),\n",
    "                     StructField('occupation', StringType(), True),\n",
    "                     StructField('relationship', StringType(), True),\n",
    "                     StructField('race', StringType(), True),\n",
    "                     StructField('sex', StringType(), True),\n",
    "                     StructField('capital_gain', LongType(), True),\n",
    "                     StructField('capital_loss', LongType(), True),\n",
    "                     StructField('hours_per_week', LongType(), True),\n",
    "                     StructField('native_country', StringType(), True),\n",
    "                     ])\n",
    "\n",
    "### Reading the csv file from s3 bucket ####\n",
    "input_df = spark.read.option(\"delimiter\", \",\").schema(schema)\\\n",
    "            .csv(\"data_files/adult.csv\")\\\n",
    "            .where((F.col('occupation')!='?') & (F.col('native_country')!='?')).limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83fafa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### creating the row number for the data \n",
    "from pyspark.sql.functions import row_number,lit\n",
    "from pyspark.sql.window import Window\n",
    "w = Window().orderBy(lit('A'))\n",
    "input_df = input_df.withColumn(\"id\", row_number().over(w))\n",
    "\n",
    "input_df.registerTempTable(\"input_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "097bb6f4-2a9f-4f3e-90f8-591191b2b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+-------------+---------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+---+\n",
      "|age|workclass       |fnlwgt|education|education_num|marital_status       |occupation       |relationship |race |sex   |capital_gain|capital_loss|hours_per_week|native_country|id |\n",
      "+---+----------------+------+---------+-------------+---------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+---+\n",
      "|39 |State-gov       |77516 |Bachelors|13           |Never-married        |Adm-clerical     |Not-in-family|White|Male  |2174        |0           |40            |United-States |1  |\n",
      "|50 |Self-emp-not-inc|83311 |Bachelors|13           |Married-civ-spouse   |Exec-managerial  |Husband      |White|Male  |0           |0           |13            |United-States |2  |\n",
      "|38 |Private         |215646|HS-grad  |9            |Divorced             |Handlers-cleaners|Not-in-family|White|Male  |0           |0           |40            |United-States |3  |\n",
      "|53 |Private         |234721|11th     |7            |Married-civ-spouse   |Handlers-cleaners|Husband      |Black|Male  |0           |0           |40            |United-States |4  |\n",
      "|28 |Private         |338409|Bachelors|13           |Married-civ-spouse   |Prof-specialty   |Wife         |Black|Female|0           |0           |40            |Cuba          |5  |\n",
      "|37 |Private         |284582|Masters  |14           |Married-civ-spouse   |Exec-managerial  |Wife         |White|Female|0           |0           |40            |United-States |6  |\n",
      "|49 |Private         |160187|9th      |5            |Married-spouse-absent|Other-service    |Not-in-family|Black|Female|0           |0           |16            |Jamaica       |7  |\n",
      "|52 |Self-emp-not-inc|209642|HS-grad  |9            |Married-civ-spouse   |Exec-managerial  |Husband      |White|Male  |0           |0           |45            |United-States |8  |\n",
      "|31 |Private         |45781 |Masters  |14           |Never-married        |Prof-specialty   |Not-in-family|White|Female|14084       |0           |50            |United-States |9  |\n",
      "|42 |Private         |159449|Bachelors|13           |Married-civ-spouse   |Exec-managerial  |Husband      |White|Male  |5178        |0           |40            |United-States |10 |\n",
      "+---+----------------+------+---------+-------------+---------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "726f5704-e580-49d2-b219-35a2311f07fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "162bcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the col span values for numerical features is diff of max and min and for categorical is distinct of column.\n",
    "def get_span(numcols, catcols, table_name):\n",
    "    query1=\"\"\n",
    "    query1+=\"\"\"SELECT 'x' partition_id,\n",
    "    tbl.id\"\"\"\n",
    "    \n",
    "    for col in numcols:\n",
    "        query1+=\"\"\",\n",
    "        tbl.{0},\n",
    "        inner_query_{0}.{0}_span\n",
    "        \"\"\".format(col)\n",
    "        \n",
    "    for col in catcols:\n",
    "        query1+=\"\"\",\n",
    "        tbl.{0},\n",
    "        inner_query_{0}.{0}_span\n",
    "        \"\"\".format(col)\n",
    "    \n",
    "    query1+=\"from {0} tbl\".format(table_name)\n",
    "    \n",
    "    for col in numcols:\n",
    "        query1+=\"\"\"\n",
    "        inner join\n",
    "        (SELECT max({0})-min({0}) {0}_span\n",
    "        FROM {1}) inner_query_{0}\n",
    "        ON 1=1\n",
    "        \"\"\".format(col,table_name)\n",
    "        \n",
    "    for col in catcols:\n",
    "        query1+=\"\"\"\n",
    "        inner join\n",
    "        (select \n",
    "        COUNT(DISTINCT {0})  {0}_span\n",
    "        FROM {1}) inner_query_{0}\n",
    "        on 1=1\n",
    "        \"\"\".format(col,table_name)\n",
    "    return query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "821acfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### calling the get_span function by passing numerical, categorical and input table\n",
    "span_df = spark.sql(get_span(numerical,categorical,'input_df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac98e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Writing into parquet file #####\n",
    "span_df.write.mode('overwrite').parquet('output_files/k_anon/fourteen_feat_30k/0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f6ba261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.func1(arr, flag)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## Implementing the udf where categorical features length were divided by 2 and registering the udf \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "def func1(arr,flag):\n",
    "    arr_mid = len(arr)//2 \n",
    "    la = arr[:arr_mid]\n",
    "    ra = arr[arr_mid:]\n",
    "    if flag == '1':\n",
    "        return la\n",
    "    elif flag == '2':\n",
    "        return ra\n",
    "    \n",
    "spark.udf.register(\"func_udf\",func1,ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "099db88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the median value for all numerical columns and for categorical calling the udf and aggregating all the elements\n",
    "def get_med_query(numcols,catcols,table_name):\n",
    "    query1=\"\"\n",
    "    query1+=\"\"\"SELECT tbl.partition_id,\n",
    "    \"\"\"\n",
    "    for col in numcols:\n",
    "        query1+=\"\"\"\n",
    "        max(tbl.{0}_span) {0}_span,\n",
    "        max(tbl.{0})-min(tbl.{0}) {0}_span_part,\n",
    "        max(inner_qr_{0}.{0}_med) {0}_med,\n",
    "        sum(case when tbl.{0} < inner_qr_{0}.{0}_med then 1 else 0 end) {0}_left_cnt,\n",
    "        sum(case when tbl.{0} >= inner_qr_{0}.{0}_med then 1 else 0 end) {0}_right_cnt,\n",
    "        \"\"\".format(col)\n",
    "        \n",
    "    for col in catcols:\n",
    "        query1+=\"\"\"\n",
    "        max(tbl.{0}_span) {0}_span,\n",
    "        count(distinct tbl.{0}) {0}_span_part,\n",
    "        max({0}_inner_q.{0}_arr_l) {0}_arr_l,\n",
    "        max({0}_inner_q.{0}_arr_r) {0}_arr_r,\n",
    "        sum(case when array_contains({0}_inner_q.{0}_arr_l,tbl.{0}) then 1 else 0 end) {0}_left_cnt,\n",
    "        sum(case when array_contains({0}_inner_q.{0}_arr_r,tbl.{0}) then 1 else 0 end) {0}_right_cnt,\n",
    "        \"\"\".format(col)\n",
    "\n",
    "    query1+=\"\"\"\n",
    "    count(*) row_cnt \n",
    "    from {0} tbl\n",
    "    \"\"\".format(table_name)\n",
    "    \n",
    "    for col in numcols:\n",
    "        query1+=\"\"\"\n",
    "        inner join \n",
    "        (select \n",
    "        partition_id,\n",
    "        percentile_approx({0}, 0.5) {0}_med\n",
    "        from {1}\n",
    "        group by\n",
    "        partition_id) inner_qr_{0}\n",
    "        on tbl.partition_id = inner_qr_{0}.partition_id\n",
    "        \"\"\".format(col,table_name)\n",
    "        \n",
    "    for col in catcols:\n",
    "        query1+=\"\"\"\n",
    "        inner join\n",
    "          (select\n",
    "          inner_tbl.partition_id,\n",
    "          func_udf(collect_set(inner_tbl.{0}),'1') {0}_arr_l,\n",
    "          func_udf(collect_set(inner_tbl.{0}),'2') {0}_arr_r\n",
    "          from {1} inner_tbl\n",
    "          group by inner_tbl.partition_id) {0}_inner_q\n",
    "        on tbl.partition_id = {0}_inner_q.partition_id\n",
    "        \"\"\".format(col,table_name)\n",
    "\n",
    "    query1+=\"\"\"\n",
    "    group by \n",
    "    tbl.partition_id\n",
    "    \"\"\"\n",
    "    return query1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f5b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Finding the span value and checking the k_anonymous criteria\n",
    "def split_col_query(cols, table_name):\n",
    "    query1 = \"\"\n",
    "    query1 += \"\"\"\n",
    "    SELECT main_tbl.partition_id,\n",
    "    main_tbl.split_col\n",
    "    from (select\n",
    "    inner_tbl.partition_id,\n",
    "    inner_tbl.split_col,\n",
    "    row_number() over (partition by inner_tbl.partition_id order by inner_tbl.span desc, inner_tbl.split_col) row_num \n",
    "    from(\n",
    "    \"\"\"\n",
    "    for col_ind in range(len(cols) - 1):\n",
    "        query1 += \"\"\"\n",
    "        select \n",
    "        partition_id, \n",
    "        '{0}' split_col, \n",
    "        {0}_span_part/{0}_span span \n",
    "        from {1}\n",
    "        where {0}_left_cnt >= 3\n",
    "        and {0}_right_cnt >= 3\n",
    "        and {0}_span > 0\n",
    "        union all\n",
    "        \"\"\".format(cols[col_ind], table_name)\n",
    "        \n",
    "    query1 += \"\"\"\n",
    "    select \n",
    "    partition_id, \n",
    "    '{0}' split_col, \n",
    "    {0}_span_part/{0}_span span \n",
    "    from {1}\n",
    "    where {0}_left_cnt >= 3\n",
    "    and {0}_right_cnt >= 3\n",
    "    and {0}_span > 0\n",
    "    \"\"\".format(cols[-1], table_name)\n",
    "    query1 += \"\"\"\n",
    "    ) inner_tbl\n",
    "    ) main_tbl\n",
    "    where main_tbl.row_num = 1\n",
    "    \"\"\"\n",
    "    return query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b8ed575",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Implemented another query for numerical the 'l' and 'r' will be appended when ever it is less than or greater \n",
    "value and for categorical it check whether the value contains in left list or right list and appended with those values ''' \n",
    "\n",
    "def final_query(numcols,catcols,main_tbl,step1_tbl,step2_tbl):\n",
    "    query1 = \"\"\n",
    "    query1 += \"\"\"\n",
    "    select\n",
    "    case \n",
    "    when step2_tbl.split_col is null then main_tbl.partition_id\n",
    "    \"\"\"\n",
    "    for col in numcols:\n",
    "        query1 += \"\"\"\n",
    "        when step2_tbl.split_col = '{0}' and main_tbl.{0} < step1_tbl.{0}_med then main_tbl.partition_id||'l'\n",
    "        when step2_tbl.split_col = '{0}' and main_tbl.{0} >= step1_tbl.{0}_med then main_tbl.partition_id||'r'\n",
    "        \"\"\".format(col)\n",
    "        \n",
    "    for col in catcols:\n",
    "        query1 += \"\"\"\n",
    "        when step2_tbl.split_col = '{0}' and array_contains(step1_tbl.{0}_arr_l,{0}) then main_tbl.partition_id||'l'\n",
    "        when step2_tbl.split_col = '{0}' and array_contains(step1_tbl.{0}_arr_r,{0}) then main_tbl.partition_id||'r'\n",
    "        \"\"\".format(col)\n",
    "        \n",
    "    query1 += \"\"\"\n",
    "    else 'unknown'\n",
    "    end partition_id,\n",
    "    step2_tbl.split_col,\n",
    "    \"\"\"\n",
    "    for col in numcols:\n",
    "        query1 += \"\"\"\n",
    "        step1_tbl.{0}_med,\n",
    "        main_tbl.{0},\n",
    "        main_tbl.{0}_span,\n",
    "        \"\"\".format(col)\n",
    "        \n",
    "    for col in catcols:\n",
    "        query1 += \"\"\"\n",
    "        step1_tbl.{0}_arr_l,\n",
    "        step1_tbl.{0}_arr_r,\n",
    "        main_tbl.{0},\n",
    "        main_tbl.{0}_span,\n",
    "        \"\"\".format(col)\n",
    "        \n",
    "    query1 += \"\"\"\n",
    "    main_tbl.id\n",
    "    from {0} main_tbl\n",
    "      inner join {1} step1_tbl\n",
    "      on main_tbl.partition_id = step1_tbl.partition_id\n",
    "      left outer join {2} step2_tbl\n",
    "      on step1_tbl.partition_id = step2_tbl.partition_id\n",
    "    \"\"\".format(main_tbl, step1_tbl, step2_tbl)\n",
    "    return query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef5d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-23 11:26:45.471627|loop: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 41626)\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "       ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o102.count",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#loop_step2_df.show(5,False)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loop_step2_df\u001b[38;5;241m.\u001b[39mregisterTempTable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloop_step2_df\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m split_cnt\u001b[38;5;241m=\u001b[39m\u001b[43mloop_step2_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|split_cnt: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(split_cnt))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_cnt\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1193\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o102.count"
     ]
    }
   ],
   "source": [
    "### Iterating the loop and running all the queries by calling those functions.\n",
    "for loop in range(0,100):\n",
    "    print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\"|loop: \"+str(loop))\n",
    "    loop_input_df=spark.read.parquet(\"output_files/k_anon/fourteen_feat_30k/\"+str(loop))\n",
    "    loop_input_df.registerTempTable(\"loop_input_df\")\n",
    "\n",
    "    med_query = get_med_query(numerical,categorical,'loop_input_df')\n",
    "    #print(med_query)\n",
    "    loop_step1_df = spark.sql(med_query)\n",
    "    #loop_step1_df.show(5,False)\n",
    "    loop_step1_df.registerTempTable(\"loop_step1_df\")\n",
    "\n",
    "    split_query = split_col_query(columns,'loop_step1_df')\n",
    "    #print(split_query)\n",
    "    loop_step2_df = spark.sql(split_query)\n",
    "    #loop_step2_df.show(5,False)\n",
    "    loop_step2_df.registerTempTable(\"loop_step2_df\")\n",
    "\n",
    "    split_cnt=loop_step2_df.count()\n",
    "    print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\"|split_cnt: \"+str(split_cnt))\n",
    "\n",
    "    if split_cnt==0:\n",
    "        break\n",
    "\n",
    "    final_1 = final_query(numerical,categorical,'loop_input_df', 'loop_step1_df', 'loop_step2_df')\n",
    "    #print(final_1)\n",
    "    loop_step3_df = spark.sql(final_1)\n",
    "    #loop_step3_df.show(5,False)\n",
    "   \n",
    "    loop_step3_df.write.parquet(\"output_files/k_anon/fourteen_feat_30k/\"+str(loop+1), mode=\"overwrite\")\n",
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\"|after write\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b456b5e",
   "metadata": {},
   "source": [
    "#### Partitioning output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "2021-09-28 14:19:07.689102|loop: 0\n",
    "2021-09-28 14:21:04.419906|split_cnt: 1\n",
    "2021-09-28 14:23:32.522937|loop: 1\n",
    "2021-09-28 14:25:32.770516|split_cnt: 2\n",
    "2021-09-28 14:28:14.736992|loop: 2\n",
    "2021-09-28 14:30:14.378372|split_cnt: 4\n",
    "2021-09-28 14:32:59.712398|loop: 3\n",
    "2021-09-28 14:35:07.356943|split_cnt: 8\n",
    "2021-09-28 14:37:57.538933|loop: 4\n",
    "2021-09-28 14:39:56.688526|split_cnt: 16\n",
    "2021-09-28 14:42:43.300846|loop: 5\n",
    "2021-09-28 14:44:51.562501|split_cnt: 32\n",
    "2021-09-28 14:47:40.254535|loop: 6\n",
    "2021-09-28 14:49:46.864529|split_cnt: 62\n",
    "2021-09-28 14:52:13.779699|loop: 7\n",
    "2021-09-28 14:54:06.315054|split_cnt: 116\n",
    "2021-09-28 14:56:42.971604|loop: 8\n",
    "2021-09-28 14:58:44.119904|split_cnt: 197\n",
    "2021-09-28 15:01:21.051039|loop: 9\n",
    "2021-09-28 15:03:21.422372|split_cnt: 292\n",
    "2021-09-28 15:05:47.163267|loop: 10\n",
    "2021-09-28 15:07:57.923257|split_cnt: 424\n",
    "2021-09-28 15:10:39.911727|loop: 11\n",
    "2021-09-28 15:12:44.807146|split_cnt: 565\n",
    "2021-09-28 15:15:25.759416|loop: 12\n",
    "2021-09-28 15:17:37.300752|split_cnt: 651\n",
    "2021-09-28 15:20:17.189181|loop: 13\n",
    "2021-09-28 15:22:32.320687|split_cnt: 713\n",
    "2021-09-28 15:25:27.629532|loop: 14\n",
    "2021-09-28 15:27:46.214194|split_cnt: 773\n",
    "2021-09-28 15:30:42.341847|loop: 15\n",
    "2021-09-28 15:33:05.059612|split_cnt: 775\n",
    "2021-09-28 15:36:16.693243|loop: 16\n",
    "2021-09-28 15:38:39.714015|split_cnt: 704\n",
    "2021-09-28 15:42:43.711305|loop: 17\n",
    "2021-09-28 15:45:26.249777|split_cnt: 616\n",
    "2021-09-28 15:48:48.732298|loop: 18\n",
    "2021-09-28 15:51:24.338337|split_cnt: 556\n",
    "2021-09-28 15:54:44.484278|loop: 19\n",
    "2021-09-28 15:57:15.783963|split_cnt: 408\n",
    "2021-09-28 16:00:37.878123|loop: 20\n",
    "2021-09-28 16:03:20.209884|split_cnt: 292\n",
    "2021-09-28 16:07:24.885998|loop: 21\n",
    "2021-09-28 16:10:20.526879|split_cnt: 133\n",
    "2021-09-28 16:14:06.677973|loop: 22\n",
    "2021-09-28 16:16:58.706909|split_cnt: 63\n",
    "2021-09-28 16:20:27.534253|loop: 23\n",
    "2021-09-28 16:23:12.840285|split_cnt: 12\n",
    "2021-09-28 16:26:50.206500|loop: 24\n",
    "2021-09-28 16:29:32.562561|split_cnt: 0\n",
    "2021-09-28 16:29:32.562686|after write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summary: 2 hours 10 minutes for all 14 cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c14921",
   "metadata": {},
   "source": [
    "#### 14 cols partition file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### writing down the last loop number in the parquet file ####\n",
    "partition_fourteen_cols = spark.read.parquet('output_files/k_anon/fourteen_feat_30k//24')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7030da",
   "metadata": {},
   "source": [
    "#### Final k_anonymised file logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Grouping by partition id and finding the mean for numerical columns and\n",
    "                    finding the aggregation of all the categorical elements '''\n",
    "from pyspark.sql import functions as F\n",
    "k_anon_agg_cols = partition_fourteen_cols.groupBy(\"partition_id\")\\\n",
    "            .agg(F.mean('age').alias('age_k_anon'),F.mean('fnlwgt').alias('fnlwgt_k_anon'),\\\n",
    "            F.mean('education_num').alias('education_num_k_anon'),F.mean('capital_gain').alias('capital_gain_k_anon'),\\\n",
    "            F.mean('capital_loss').alias('capital_loss_k_anon'),F.mean('hours_per_week').alias('hours_per_week_k_anon'),\\\n",
    "            F.collect_set('workclass').alias('workclass_k_anon'),F.collect_set('education').alias('education_k_anon'),\\\n",
    "            F.collect_set('marital_status').alias('marital_status_k_anon'),F.collect_set('occupation').alias('occupation_k_anon'),\\\n",
    "            F.collect_set('relationship').alias('relationship_k_anon'),F.collect_set('sex').alias('sex_k_anon'),\\\n",
    "            F.collect_set('native_country').alias('native_country_k_anon'),F.collect_set('race').alias('race_k_anon'))\\\n",
    ".withColumn('age_k_anon',F.round(F.col('age_k_anon'),2)).withColumn('fnlwgt_k_anon',F.round(F.col('fnlwgt_k_anon'),2))\\\n",
    ".withColumn('education_num_k_anon',F.round(F.col('education_num_k_anon'),2)).withColumn('capital_gain_k_anon',F.round(F.col('capital_gain_k_anon'),2))\\\n",
    ".withColumn('capital_loss_k_anon',F.round(F.col('capital_loss_k_anon'),2)).withColumn('hours_per_week_k_anon',F.round(F.col('hours_per_week_k_anon'),2))\n",
    "\n",
    "# Joining with partition id by joining the above aggregated columns and partition dataframe ##\n",
    "k_anon_fourteen_cols = k_anon_agg_cols.join(partition_fourteen_cols,['partition_id'],how='inner').orderBy('partition_id')\\\n",
    "    .select('partition_id','age','fnlwgt','workclass','education','education_num','marital_status','occupation','relationship',\\\n",
    "            'race','sex','capital_gain','capital_loss','hours_per_week','native_country','age_k_anon','fnlwgt_k_anon',\\\n",
    "            'workclass_k_anon','education_k_anon','education_num_k_anon','marital_status_k_anon','occupation_k_anon',\\\n",
    "            'relationship_k_anon','race_k_anon','sex_k_anon','capital_gain_k_anon','capital_loss_k_anon',\\\n",
    "            'hours_per_week_k_anon','native_country_k_anon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e63669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_anon_fourteen_cols.write.mode('overwrite').parquet(\"s3://oneid-datascience-us-east-1/Adam/data/ayyappa/k_anon/k_anonymised_14_cols\")\n",
    "\n",
    "k_anon_cols_14 = spark.read.parquet(\"output_files/k_anon/k_anonymised_14_cols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae0baa4",
   "metadata": {},
   "source": [
    "#### Final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "+----------------+---+------+----------------+------------+-------------+------------------+-----------------+------------+------------------+----+------------+------------+--------------+--------------+----------+-------------+-------------------------------+-----------------------+--------------------+---------------------+--------------------------------------------------+-------------------+--------------------+----------+-------------------+-------------------+---------------------+----------------------------+\n",
    "|partition_id    |age|fnlwgt|workclass       |education   |education_num|marital_status    |occupation       |relationship|race              |sex |capital_gain|capital_loss|hours_per_week|native_country|age_k_anon|fnlwgt_k_anon|workclass_k_anon               |education_k_anon       |education_num_k_anon|marital_status_k_anon|occupation_k_anon                                 |relationship_k_anon|race_k_anon         |sex_k_anon|capital_gain_k_anon|capital_loss_k_anon|hours_per_week_k_anon|native_country_k_anon       |\n",
    "+----------------+---+------+----------------+------------+-------------+------------------+-----------------+------------+------------------+----+------------+------------+--------------+--------------+----------+-------------+-------------------------------+-----------------------+--------------------+---------------------+--------------------------------------------------+-------------------+--------------------+----------+-------------------+-------------------+---------------------+----------------------------+\n",
    "|xrrrlrlrrllllrrl|47 |340982|Private         |Some-college|10           |Married-civ-spouse|Machine-op-inspct|Husband     |Asian-Pac-Islander|Male|3103        |0           |40            |Philippines   |47.67     |172878.33    |[Private]                      |[Some-college]         |10.0                |[Married-civ-spouse] |[Machine-op-inspct, Craft-repair, Exec-managerial]|[Husband]          |[Asian-Pac-Islander]|[Male]    |1034.33            |0.0                |40.0                 |[Philippines, United-States]|\n",
    "|xrrrlrlrrllllrrl|47 |95680 |Private         |Some-college|10           |Married-civ-spouse|Exec-managerial  |Husband     |Asian-Pac-Islander|Male|0           |0           |40            |United-States |47.67     |172878.33    |[Private]                      |[Some-college]         |10.0                |[Married-civ-spouse] |[Machine-op-inspct, Craft-repair, Exec-managerial]|[Husband]          |[Asian-Pac-Islander]|[Male]    |1034.33            |0.0                |40.0                 |[Philippines, United-States]|\n",
    "|xrrrlrlrrllllrrl|49 |81973 |Private         |Some-college|10           |Married-civ-spouse|Craft-repair     |Husband     |Asian-Pac-Islander|Male|0           |0           |40            |United-States |47.67     |172878.33    |[Private]                      |[Some-college]         |10.0                |[Married-civ-spouse] |[Machine-op-inspct, Craft-repair, Exec-managerial]|[Husband]          |[Asian-Pac-Islander]|[Male]    |1034.33            |0.0                |40.0                 |[Philippines, United-States]|\n",
    "|xrrrlrlrrllllrrr|59 |81973 |Private         |Masters     |14           |Married-civ-spouse|Exec-managerial  |Husband     |Asian-Pac-Islander|Male|0           |0           |40            |United-States |55.0      |120224.25    |[Private]                      |[Masters, Prof-school] |14.25               |[Married-civ-spouse] |[Craft-repair, Exec-managerial]                   |[Husband]          |[Asian-Pac-Islander]|[Male]    |1824.5             |475.5              |41.25                |[Philippines, United-States]|\n",
    "|xrrrlrlrrllllrrr|54 |139850|Private         |Masters     |14           |Married-civ-spouse|Exec-managerial  |Husband     |Asian-Pac-Islander|Male|0           |0           |45            |United-States |55.0      |120224.25    |[Private]                      |[Masters, Prof-school] |14.25               |[Married-civ-spouse] |[Craft-repair, Exec-managerial]                   |[Husband]          |[Asian-Pac-Islander]|[Male]    |1824.5             |475.5              |41.25                |[Philippines, United-States]|\n",
    "|xrrrlrlrrllllrrr|50 |160724|Private         |Masters     |14           |Married-civ-spouse|Exec-managerial  |Husband     |Asian-Pac-Islander|Male|7298        |0           |40            |Philippines   |55.0      |120224.25    |[Private]                      |[Masters, Prof-school] |14.25               |[Married-civ-spouse] |[Craft-repair, Exec-managerial]                   |[Husband]          |[Asian-Pac-Islander]|[Male]    |1824.5             |475.5              |41.25                |[Philippines, United-States]|\n",
    "|xrrrlrlrrllllrrr|57 |98350 |Private         |Prof-school |15           |Married-civ-spouse|Craft-repair     |Husband     |Asian-Pac-Islander|Male|0           |1902        |40            |Philippines   |55.0      |120224.25    |[Private]                      |[Masters, Prof-school] |14.25               |[Married-civ-spouse] |[Craft-repair, Exec-managerial]                   |[Husband]          |[Asian-Pac-Islander]|[Male]    |1824.5             |475.5              |41.25                |[Philippines, United-States]|\n",
    "|xrrrlrlrrlllr   |48 |82098 |Self-emp-not-inc|Some-college|10           |Married-civ-spouse|Exec-managerial  |Husband     |Asian-Pac-Islander|Male|0           |0           |65            |United-States |51.67     |77992.67     |[Self-emp-not-inc, Federal-gov]|[Some-college, Masters]|12.67               |[Married-civ-spouse] |[Exec-managerial]                                 |[Husband]          |[Asian-Pac-Islander]|[Male]    |0.0                |0.0                |55.0                 |[Philippines, United-States]|\n",
    "|xrrrlrlrrlllr   |55 |88876 |Federal-gov     |Masters     |14           |Married-civ-spouse|Exec-managerial  |Husband     |Asian-Pac-Islander|Male|0           |0           |60            |United-States |51.67     |77992.67     |[Self-emp-not-inc, Federal-gov]|[Some-college, Masters]|12.67               |[Married-civ-spouse] |[Exec-managerial]                                 |[Husband]          |[Asian-Pac-Islander]|[Male]    |0.0                |0.0                |55.0                 |[Philippines, United-States]|\n",
    "|xrrrlrlrrlllr   |52 |63004 |Self-emp-not-inc|Masters     |14           |Married-civ-spouse|Exec-managerial  |Husband     |Asian-Pac-Islander|Male|0           |0           |40            |Philippines   |51.67     |77992.67     |[Self-emp-not-inc, Federal-gov]|[Some-college, Masters]|12.67               |[Married-civ-spouse] |[Exec-managerial]                                 |[Husband]          |[Asian-Pac-Islander]|[Male]    |0.0                |0.0                |55.0                 |[Philippines, United-States]|\n",
    "+----------------+---+------+----------------+------------+-------------+------------------+-----------------+------------+------------------+----+------------+------------+--------------+--------------+----------+-------------+-------------------------------+-----------------------+--------------------+---------------------+--------------------------------------------------+-------------------+--------------------+----------+-------------------+-------------------+---------------------+----------------------------+\n",
    "only showing top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724f423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976f289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd877f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b157a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4b612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95a692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a08df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c61f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73314212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de76fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9cf6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02eb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaea081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5210f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6c25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25666a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece0547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e80b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6fe0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f6645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05dcb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba3e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775650fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b547a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11828a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3903359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd726061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261abb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c6502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8429b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242f0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b706f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62855e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba62d40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27065e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f5990c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f36560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b73326d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
